{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import relevent libraries\n\nimport numpy as np \nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nfrom sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler,MinMaxScaler,PowerTransformer,FunctionTransformer\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier,LassoCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-12T03:34:34.893159Z","iopub.execute_input":"2021-11-12T03:34:34.893619Z","iopub.status.idle":"2021-11-12T03:34:37.432517Z","shell.execute_reply.started":"2021-11-12T03:34:34.893578Z","shell.execute_reply":"2021-11-12T03:34:37.431574Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"heading\"><span style=\"font-size:36px;\">Load Data:</span></h1>","metadata":{}},{"cell_type":"code","source":"#Import csv data into dataframe object\ndata=pd.read_csv('/kaggle/input/heart-failure-prediction/heart.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:37.434267Z","iopub.execute_input":"2021-11-12T03:34:37.434486Z","iopub.status.idle":"2021-11-12T03:34:37.454021Z","shell.execute_reply.started":"2021-11-12T03:34:37.434459Z","shell.execute_reply":"2021-11-12T03:34:37.453330Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">Display first 5 rows and column info</span>","metadata":{}},{"cell_type":"code","source":"#Show overview of data structure\ndisplay(data.head())\n\n#Look for missing values\nprint(data.info())","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:37.455088Z","iopub.execute_input":"2021-11-12T03:34:37.455939Z","iopub.status.idle":"2021-11-12T03:34:37.497895Z","shell.execute_reply.started":"2021-11-12T03:34:37.455902Z","shell.execute_reply":"2021-11-12T03:34:37.497276Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"There are no missing values in the dataset","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:36px;\">EDA:</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">Separate Numerical and Categorical Columns</span>\n* This is helpful in plotting and analyzing the two types of data separately","metadata":{}},{"cell_type":"code","source":"##Select low cardinality categorical columns and numerical columns separately\ncat_col = [coln for coln in data.columns if data[coln].nunique() < 10 and\n               data[coln].dtype == 'object']\nnum_col = [coln for coln in data.columns if data[coln].dtype in ['int64','float64']]","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:37.498974Z","iopub.execute_input":"2021-11-12T03:34:37.499225Z","iopub.status.idle":"2021-11-12T03:34:37.507893Z","shell.execute_reply.started":"2021-11-12T03:34:37.499164Z","shell.execute_reply":"2021-11-12T03:34:37.507077Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Create separate dataframe (DF) for numerical and catagorical columns\ndata_num=data[num_col].copy()\ndata_cat=data[cat_col].copy()","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:37.510037Z","iopub.execute_input":"2021-11-12T03:34:37.510427Z","iopub.status.idle":"2021-11-12T03:34:37.520735Z","shell.execute_reply.started":"2021-11-12T03:34:37.510396Z","shell.execute_reply":"2021-11-12T03:34:37.520001Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Create function to show description of numerical data\ndef describedata(data):      #data === dataframe name\n    item=data.columns.tolist()\n    describelist=[]\n    for cols in item:\n        x=data[cols].describe()\n        describelist.append(x)\n    print(describelist)\n    \ndescribedata(data_num)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:37.522115Z","iopub.execute_input":"2021-11-12T03:34:37.522629Z","iopub.status.idle":"2021-11-12T03:34:37.553161Z","shell.execute_reply.started":"2021-11-12T03:34:37.522586Z","shell.execute_reply":"2021-11-12T03:34:37.552513Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"* RestingBP and Cholesterol have nonphysical values (0's) which are outliers: Investigate further","metadata":{}},{"cell_type":"code","source":"#Show outliers within the data and see how to resolve\nprint('RestingBP rows which are 0')\nprint(data_num[data_num['RestingBP']==0])\nprint('Cholesterol rows which are 0')\nprint(data_num[data_num['Cholesterol']==0])","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:37.554361Z","iopub.execute_input":"2021-11-12T03:34:37.554959Z","iopub.status.idle":"2021-11-12T03:34:37.571407Z","shell.execute_reply.started":"2021-11-12T03:34:37.554925Z","shell.execute_reply":"2021-11-12T03:34:37.570479Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"* We can remove index 449 as it contains both problems  \n* Cholesterol has a large percentage of 0's (172/918 rows), we can try to remove them and see how it affects the accuracy score","metadata":{}},{"cell_type":"code","source":"#Drop the problem row and create new dataset without \"Cholesterol\" outliers\ndata=data.drop([449])\ndata_drop_cholesterol=data[data['Cholesterol']>0]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:37.572864Z","iopub.execute_input":"2021-11-12T03:34:37.573711Z","iopub.status.idle":"2021-11-12T03:34:37.580931Z","shell.execute_reply.started":"2021-11-12T03:34:37.573655Z","shell.execute_reply":"2021-11-12T03:34:37.580251Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:36px;\">Numerical Plots and Correlations:</span>","metadata":{}},{"cell_type":"code","source":"#Overview of the correlations between all variables\nsns.heatmap(data.corr(),annot=True,cmap=\"YlGnBu\")","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:37.582072Z","iopub.execute_input":"2021-11-12T03:34:37.582658Z","iopub.status.idle":"2021-11-12T03:34:38.235797Z","shell.execute_reply.started":"2021-11-12T03:34:37.582624Z","shell.execute_reply":"2021-11-12T03:34:38.234885Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"*Negative Correlations with Heart Disease*\n* Cholesterol\n* MaxHR\n* RestingBP\n\n*Positive Correlations with Heart Disease*\n* Oldpeak\n* Age\n* FastingBS\n","metadata":{}},{"cell_type":"code","source":"#Full print of correlation matrix\ncorr_matrix=data.corr()\nprint(corr_matrix)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:38.237228Z","iopub.execute_input":"2021-11-12T03:34:38.237927Z","iopub.status.idle":"2021-11-12T03:34:38.247784Z","shell.execute_reply.started":"2021-11-12T03:34:38.237887Z","shell.execute_reply":"2021-11-12T03:34:38.247148Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Selects highly correlated  independent features \n#it will select the first feature that is correlated with anything other feature\n\ndef correlation(df,threshold):     \n    #df == dataframe, threshold == decimal value of correlation threshold\n    coll_corr=set() #set of all the names of correlated columns \n    corr_matrix=df.corr()\n    for i in range (len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i,j])> threshold:\n                colname=corr_matrix.columns[i] #getting the name of columns\n                coll_corr.add(colname)\n    return coll_corr","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:38.248863Z","iopub.execute_input":"2021-11-12T03:34:38.249561Z","iopub.status.idle":"2021-11-12T03:34:38.255310Z","shell.execute_reply.started":"2021-11-12T03:34:38.249528Z","shell.execute_reply":"2021-11-12T03:34:38.254627Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#calling the fuction to check for correlated features\ncorr_feature = correlation(data.iloc[:,:-1],0.85)\nlen(set(corr_feature))","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:38.256491Z","iopub.execute_input":"2021-11-12T03:34:38.257343Z","iopub.status.idle":"2021-11-12T03:34:38.273058Z","shell.execute_reply.started":"2021-11-12T03:34:38.257309Z","shell.execute_reply":"2021-11-12T03:34:38.272153Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"* There are zero highly correlated variables\n* Let's try to see if any variables are multicolinear with a lower threshold","metadata":{}},{"cell_type":"code","source":"#Detect multicolinearity with variance inflation factor\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nvif_data = pd.DataFrame()\nvif_data[\"feature\"] = data_num.columns\nvif_data[\"VIF\"] = [variance_inflation_factor(data_num.values, i) \n                   for i in range(len(data_num.columns))]\nfor i in range(len(vif_data.values)):\n    if vif_data.iloc[i,1]>10.0:\n        print(vif_data.iloc[i,0]+\" has a large VIF\")\n        \nvif_data = vif_data.sort_values('VIF',ascending=False)\ndisplay(vif_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:38.274419Z","iopub.execute_input":"2021-11-12T03:34:38.274759Z","iopub.status.idle":"2021-11-12T03:34:38.416373Z","shell.execute_reply.started":"2021-11-12T03:34:38.274730Z","shell.execute_reply":"2021-11-12T03:34:38.415636Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"* Age-RestingBP-MaxHR are multicolinear with a large VIF>10\n* We can try to leave **MaxHR** and discard others as MaxHR has highest correlation with target variable ","metadata":{}},{"cell_type":"code","source":"#Create new df without 'Age' and 'RestingBP' features \ndata_drop_colinear = data.drop(['Age','RestingBP'],axis=1)\n\n#Create new df without 'Age' and 'RestingBP' features  and with cholesterol empty rows dropped\ndata_drop_both=data_drop_colinear[data_drop_colinear['Cholesterol']>0]","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:38.421314Z","iopub.execute_input":"2021-11-12T03:34:38.421753Z","iopub.status.idle":"2021-11-12T03:34:38.428623Z","shell.execute_reply.started":"2021-11-12T03:34:38.421718Z","shell.execute_reply":"2021-11-12T03:34:38.427716Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:36px;\">Catagorical Plots and Correlation with Target Variable</span>","metadata":{}},{"cell_type":"code","source":"#Create function to plot numerical distributions\n\ndef num_plot(data, col):   \n    #data == dataframe to plot, col = feature to plot\n    fig = px.histogram(data, x=col, color=\"HeartDisease\",\n                       marginal=\"box\")\n    fig.update_layout(height=300, width=500, showlegend=True)\n    fig.update_traces(marker_line_width=1,marker_line_color=\"black\")\n    fig.show()\n \n \n#plot the data\nfor col in num_col:\n    num_plot(data,col)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:38.430684Z","iopub.execute_input":"2021-11-12T03:34:38.431329Z","iopub.status.idle":"2021-11-12T03:34:40.216894Z","shell.execute_reply.started":"2021-11-12T03:34:38.431274Z","shell.execute_reply":"2021-11-12T03:34:40.216081Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"* There are skewed features which can be normalized: Oldpeak, MaxHR(maybe)","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:36px;\">Analyze Catagorical Data</span>","metadata":{}},{"cell_type":"code","source":"#Function that groups Heart Disease with different training variables and calculates mean count\ndef mean_groupby(Feature,TargetVariable):\n    datagroups=data.groupby(Feature)[TargetVariable].mean().sort_values(ascending=False)*100\n    return datagroups\n\n#Plot histogram of training variables and color by positive/negative Heart Disease\ndef plot_hist_cat(Feature,TargetVariable):\n    fig = px.histogram(data_frame = data,\n             x = Feature,\n             color=TargetVariable, title=Feature + \" vs \" + TargetVariable,\n             pattern_shape_sequence=['x'], width=500,height=300)\n    fig.show()\n\n#Run last two functions for each column\nfor col in cat_col:\n    temp = mean_groupby(col,'HeartDisease')\n    print(temp)\n    print(\"\")\n    plot_hist_cat(col,'HeartDisease')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.218375Z","iopub.execute_input":"2021-11-12T03:34:40.218822Z","iopub.status.idle":"2021-11-12T03:34:40.603869Z","shell.execute_reply.started":"2021-11-12T03:34:40.218780Z","shell.execute_reply":"2021-11-12T03:34:40.603045Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"* Twice as many men get heart disease as women\n* ASY ChestPain is strong indicator of heart disease\n* Exercise Angina is strong indicator of heart disease\n* Up slope is strong indicator of no heart disease ","metadata":{}},{"cell_type":"code","source":"#let find the skewed col and fix them\n    \nskew_limit=0.75 # limit for skewed col\nskew_vals=data[num_col].drop('FastingBS', axis=1).skew()\nskew_col=skew_vals[abs(skew_vals)>skew_limit].sort_values(ascending =False)\nprint('Skewed Feature:',skew_col)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.605340Z","iopub.execute_input":"2021-11-12T03:34:40.605632Z","iopub.status.idle":"2021-11-12T03:34:40.617267Z","shell.execute_reply.started":"2021-11-12T03:34:40.605593Z","shell.execute_reply":"2021-11-12T03:34:40.616264Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Oldpeak is a heavily skewed feature that can be renormalized","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:36px;\">Split into Train/Test Sets</span>","metadata":{}},{"cell_type":"code","source":"#create function to split data\ny=data.HeartDisease\nX=data.drop(['HeartDisease'],axis=1)\nX_dropchol=data_drop_cholesterol.drop(['HeartDisease'],axis=1)  #dropped cholesterol=0 rows \ny_dropchol=data_drop_cholesterol.HeartDisease\nX_dropcolin=data_drop_colinear.drop(['HeartDisease'],axis=1)  #dropped multicolinear columns\nX_dropboth=data_drop_both.drop(['HeartDisease'],axis=1) #dropped cholesterol=0 rows and multicolinear columns\n\n#Create function to split into training and test data\ndef splitdata(data,y):\n    X_train_all,X_test_all,y_train,y_test=train_test_split(data,y,train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n    return X_train_all,X_test_all,y_train,y_test","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.618814Z","iopub.execute_input":"2021-11-12T03:34:40.619222Z","iopub.status.idle":"2021-11-12T03:34:40.631804Z","shell.execute_reply.started":"2021-11-12T03:34:40.619154Z","shell.execute_reply":"2021-11-12T03:34:40.631079Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Split all data to test\nX_train_all,X_test_all,y_train,y_test=splitdata(X,y)\nX_train_chol,X_test_chol,y_train_chol,y_test_chol=splitdata(X_dropchol,y_dropchol)\nX_train_colin,X_test_colin,y_train_colin,y_test_colin=splitdata(X_dropcolin,y)\nX_train_both,X_test_both,y_train_both,y_test_both=splitdata(X_dropboth,y_dropchol)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.632821Z","iopub.execute_input":"2021-11-12T03:34:40.633042Z","iopub.status.idle":"2021-11-12T03:34:40.649860Z","shell.execute_reply.started":"2021-11-12T03:34:40.633017Z","shell.execute_reply":"2021-11-12T03:34:40.649102Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:36px;\">Preprocess Data</span>","metadata":{}},{"cell_type":"markdown","source":"Fix skewed feature","metadata":{"execution":{"iopub.status.busy":"2021-10-19T01:16:08.772211Z","iopub.execute_input":"2021-10-19T01:16:08.772579Z","iopub.status.idle":"2021-10-19T01:16:08.778243Z","shell.execute_reply.started":"2021-10-19T01:16:08.772542Z","shell.execute_reply":"2021-10-19T01:16:08.777354Z"}}},{"cell_type":"code","source":"#fix skew using power transformer to make data more gaussian like \ndatalist=[X_train_all,X_test_all,X_train_chol,X_test_chol,X_train_colin,X_test_colin,X_train_both,X_test_both] #list of datasets\n#cat_col_colin = ['Sex', 'ChestPainType','RestingECG',\n                #'ExerciseAngina', 'ST_Slope']\ncat_col_list=[cat_col,cat_col,cat_col,cat_col,cat_col,cat_col,cat_col,cat_col] #list of category columns\nskewfeature=['Oldpeak']\n\ndef fixskew(skewfeature,datalist):\n    pt=PowerTransformer(standardize=False)\n    datalistnew=[]\n    length=len(datalist)-1\n    for i in np.arange(0,length,2):\n        tempdata=datalist[i]\n        tempdata[skewfeature]=pt.fit_transform(tempdata[skewfeature])\n        datalistnew.append(tempdata)\n        tempdata1=datalist[i+1]\n        tempdata1[skewfeature]=pt.transform(tempdata1[skewfeature])\n        datalistnew.append(tempdata1)\n    return datalistnew\n\n\ndatalistnew=fixskew(skewfeature,datalist) #contains all split data with fixed skew\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.651143Z","iopub.execute_input":"2021-11-12T03:34:40.651547Z","iopub.status.idle":"2021-11-12T03:34:40.697819Z","shell.execute_reply.started":"2021-11-12T03:34:40.651503Z","shell.execute_reply":"2021-11-12T03:34:40.696960Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Encode Catagorical Data","metadata":{}},{"cell_type":"code","source":"#Function to Encode catagorical data into columns of 1's and 0's\ndef EncodeCat(data_list,cat_col_list):\n    encode_data=[]\n    length=len(data_list)-1\n    for i in np.arange(0,length,2):\n        temptrain=data_list[i]\n        temptest=data_list[i+1]\n        tempcol=cat_col_list[i]\n        temptrain=pd.get_dummies(temptrain,columns=tempcol,drop_first=True)\n        temptest=pd.get_dummies(temptest,columns=tempcol,drop_first=True)\n        encode_data.append(temptrain)\n        encode_data.append(temptest)\n    return encode_data\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.699641Z","iopub.execute_input":"2021-11-12T03:34:40.700267Z","iopub.status.idle":"2021-11-12T03:34:40.708487Z","shell.execute_reply.started":"2021-11-12T03:34:40.700220Z","shell.execute_reply":"2021-11-12T03:34:40.707697Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#Create list of encoded data\nencode_data_list = EncodeCat(datalistnew,cat_col_list)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.709896Z","iopub.execute_input":"2021-11-12T03:34:40.710674Z","iopub.status.idle":"2021-11-12T03:34:40.764783Z","shell.execute_reply.started":"2021-11-12T03:34:40.710612Z","shell.execute_reply":"2021-11-12T03:34:40.763695Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Scale all data columns with standard scaler\n* Centers data based on the mean\n* Normalizes data with standard deviation","metadata":{}},{"cell_type":"code","source":"#Use standard scaler to normalize data \ndef ScalerFunc(datalist):  #returns list of processed data\n    sc=StandardScaler()\n    length=len(datalist)-1\n    data_prefinal=[]\n    for i in np.arange(0,length,2):\n        tempdatatrain=datalist[i]\n        tempdatatest=datalist[i+1]\n        X_train_scaled=sc.fit_transform(tempdatatrain)\n        X_test_scaled=sc.transform(tempdatatest)\n        X_train = pd.DataFrame(X_train_scaled, columns = tempdatatrain.columns[:])\n        X_test = pd.DataFrame(X_test_scaled, columns = tempdatatest.columns[:])\n        data_prefinal.append(X_train)\n        data_prefinal.append(X_test)\n    return data_prefinal\n \n#list of processed data\ndata_prefinal=ScalerFunc(encode_data_list)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.765985Z","iopub.execute_input":"2021-11-12T03:34:40.766254Z","iopub.status.idle":"2021-11-12T03:34:40.799447Z","shell.execute_reply.started":"2021-11-12T03:34:40.766217Z","shell.execute_reply":"2021-11-12T03:34:40.798649Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"y_list = [y_train,y_test,y_train_chol,y_test_chol,y_train,y_test,y_train_chol,y_test_chol]\n#data_final=DropCols(data_prefinal,drop_cols)\n\ndef models_score(models,datalist,y_list):# (model is dict, datalist contains x values, y list)   \n    #returns list of scores of each model\n    scores = {}\n    length = len(datalist)-1\n    model_list=[]\n    for i in np.arange(0,length,2):\n        X_train=datalist[i]\n        X_test=datalist[i+1]\n        y_train = y_list[i]\n        y_test = y_list[i+1]\n        print(\"\")\n        print(\"\")\n        print(\"\")\n        for name, model in models.items():\n            model.fit(X_train, y_train)\n            y_pred=model.predict(X_test) \n            scores[name] = model.score(X_test,y_test)\n            #printing the model name and accuracy !!!!!\n            print(\"Model name: \",model)\n            print(\"Accuracy :--->>\",accuracy_score(y_test,y_pred))\n            print()\n            print(classification_report(y_test,y_pred))\n            print(\"Confusion matrix:--->>\\n\",confusion_matrix(y_test,y_pred)) \n            print(\"\\n<<<<------------------------------------------------------------->>>>\\n\")\n           \n   \n        model_scores = pd.DataFrame(scores, index=['Score']).transpose()\n        model_scores = model_scores.sort_values('Score',ascending=False)\n        model_list.append(model_scores)\n    return model_list","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.800602Z","iopub.execute_input":"2021-11-12T03:34:40.800848Z","iopub.status.idle":"2021-11-12T03:34:40.811840Z","shell.execute_reply.started":"2021-11-12T03:34:40.800818Z","shell.execute_reply":"2021-11-12T03:34:40.810947Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#Dictionary of models to test\nmodels = {\"LogisticRegression\":LogisticRegression(solver=\"liblinear\"),\n          \"SVC\":SVC(C= 1.0,gamma= 0.05,kernel='rbf'),\n          \"DecisionTree\":DecisionTreeClassifier(criterion='gini',max_depth=5,max_features='auto',splitter='random'),\n          \"AdaBoost\":AdaBoostClassifier(algorithm='SAMME',learning_rate= 0.1,n_estimators=150),\n          \"GradiantBoost\":GradientBoostingClassifier(criterion='friedman_mse',learning_rate=0.05,loss='exponential',n_estimators=100),\n         \"RandomForest\":RandomForestClassifier(criterion='gini',n_estimators=150),\n         \"XgBoost\": XGBClassifier(learning_rate=0.1,n_estimators=150),\n         \"KNeighborsClassifier\":KNeighborsClassifier(n_neighbors=7)}","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.813551Z","iopub.execute_input":"2021-11-12T03:34:40.814107Z","iopub.status.idle":"2021-11-12T03:34:40.827975Z","shell.execute_reply.started":"2021-11-12T03:34:40.814062Z","shell.execute_reply":"2021-11-12T03:34:40.827311Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#Run all models on various datasets and print results\nmodel_scores = models_score(models,data_prefinal,y_list)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:40.829621Z","iopub.execute_input":"2021-11-12T03:34:40.830238Z","iopub.status.idle":"2021-11-12T03:34:45.374396Z","shell.execute_reply.started":"2021-11-12T03:34:40.830148Z","shell.execute_reply":"2021-11-12T03:34:45.373517Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Prints accuracy score of each model set","metadata":{}},{"cell_type":"code","source":"print(\"Model which includes all training elements\")\ntemp_model_scores=model_scores[0]\ntemp_model_scores=temp_model_scores.reset_index().rename({\"index\":\"Algorithms\"}, axis = 1)\ntemp_model_scores.style.bar()\ndisplay(temp_model_scores)\nprint('')\n\nprint(\"Model which excludes empty 'Cholesterol' rows\")\ntemp_model_scores1=model_scores[1]\ntemp_model_scores1=temp_model_scores1.reset_index().rename({\"index\":\"Algorithms\"}, axis = 1)\ntemp_model_scores1.style.bar()\ndisplay(temp_model_scores1)\nprint('')\n\nprint(\"Model which excludes colinear training variables\")\ntemp_model_scores2=model_scores[2]\ntemp_model_scores2=temp_model_scores2.reset_index().rename({\"index\":\"Algorithms\"}, axis = 1)\ntemp_model_scores2.style.bar()\ndisplay(temp_model_scores2)\nprint('')\n\nprint(\"Model which excludes colinear training variables and empty cholesterol values\")\ntemp_model_scores3=model_scores[3]\ntemp_model_scores3=temp_model_scores2.reset_index().rename({\"index\":\"Algorithms\"}, axis = 1)\ntemp_model_scores3.style.bar()\ndisplay(temp_model_scores2)\nprint('')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-12T03:34:45.375720Z","iopub.execute_input":"2021-11-12T03:34:45.376535Z","iopub.status.idle":"2021-11-12T03:34:45.483693Z","shell.execute_reply.started":"2021-11-12T03:34:45.376495Z","shell.execute_reply":"2021-11-12T03:34:45.482809Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"* ADA boost on the dataset with Cholesterol=0 rows removed had best score ~91%\n* The dataset with colinear features and Cholesterol=0 rows removed had best average score","metadata":{}},{"cell_type":"code","source":"#Plot bar graph of accuracy score of each model for best dataset\n\nfig = px.bar(data_frame = temp_model_scores1,\n             x=\"Algorithms\",\n             y=\"Score\",\n             color=\"Algorithms\", title = \"<b>Models Score without Cholesterol 0's</b>\", template = 'plotly_dark')\n\nfig.update_layout(bargap=0.2)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:02:48.234962Z","iopub.execute_input":"2021-11-12T04:02:48.235284Z","iopub.status.idle":"2021-11-12T04:02:48.335796Z","shell.execute_reply.started":"2021-11-12T04:02:48.235248Z","shell.execute_reply":"2021-11-12T04:02:48.334941Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}